# ğŸŒ LLOT - Local LLM Ollama Translator

> **Privacy-first translation service for self-hosters**  
> No API keys â€¢ No cloud services â€¢ No data collection â€¢ 100% local

[![Self-Hosted](https://img.shields.io/badge/Self--Hosted-100%25-green?style=for-the-badge&logo=docker)](https://github.com/pawelwiejkut/llot)
[![Languages](https://img.shields.io/badge/Languages-40%2B-blue?style=for-the-badge)](https://github.com/pawelwiejkut/llot)
[![Privacy](https://img.shields.io/badge/Privacy-First-red?style=for-the-badge&logo=shield)](https://github.com/pawelwiejkut/llot)

## âœ¨ Why Self-Hosters Love LLOT

| ğŸ”’ **Total Privacy** | âš¡ **Lightning Fast** | ğŸ  **Homelab Ready** |
|:---:|:---:|:---:|
| Your data never leaves your network | Real-time translation as you type | Docker deployment in minutes |

| ğŸŒ **40+ Languages** | ğŸ”Š **Neural TTS** | ğŸ”§ **Your Infrastructure** |
|:---:|:---:|:---:|
| Multilingual interface + smart detection | High-quality speech for 20+ languages | Use existing servers or install locally |  

![LLOT Interface](docs/images/llot-interface.png)
*Real-time translation with smart language detection and neural TTS*

---

## ğŸš€ Quick Start

### Option 1: Guided Setup (Recommended)
```bash
git clone https://github.com/pawelwiejkut/llot.git
cd llot
./setup.sh  # Interactive setup wizard
```

![Setup Demo](docs/images/setup-demo.svg)
*Interactive setup wizard guides you through configuration*

### Option 2: One-Line Deploy
```bash
# With your existing Ollama server
git clone https://github.com/pawelwiejkut/llot.git && cd llot
echo "OLLAMA_HOST=http://your-ollama-server:11434" > .env
docker-compose up -d
```

### Option 3: Complete Local Setup
```bash
# Installs everything locally (Ollama + Wyoming Piper)
git clone https://github.com/pawelwiejkut/llot.git && cd llot
docker-compose -f docker-compose.full.yml up -d
```

**ğŸ¯ Access LLOT:** http://localhost:8080

---

## ğŸ—ï¸ Architecture Options

Choose what fits your homelab:

### ğŸŒ **Microservices** (Recommended)
```yaml
LLOT: Docker container
Ollama: External server (your existing setup)
Wyoming Piper: External server (optional TTS)
```
**Perfect for:** Existing homelab infrastructure, resource optimization

### ğŸ–¥ï¸ **All-in-One**  
```yaml
LLOT + Ollama + Wyoming: Single docker-compose
```
**Perfect for:** New deployments, single-server setups

### â˜ï¸ **Hybrid Cloud**
```yaml
LLOT: Local Docker
Ollama: Cloud GPU instance
Wyoming: Local container
```
**Perfect for:** GPU acceleration with local privacy

---

## âš™ï¸ Configuration

### Quick Config (.env)
```bash
# Your Ollama server
OLLAMA_HOST=http://your-ollama-server:11434
OL_MODEL=gemma3:27b

# Optional: Wyoming Piper for TTS
WYOMING_PIPER_HOST=your-piper-server
WYOMING_PIPER_PORT=10200

# Optional: Limit languages
TRANSLATION_LANGUAGES=en,de,pl,es,fr
```

### Recommended Models
- **`gemma3:27b`** - Best quality (32GB RAM)
- **`llama3:8b`** - Balanced (8GB RAM)
- **`mistral:7b`** - Lightweight (4GB RAM)

---

## ğŸ”Š Text-to-Speech Support

**âœ… Supported Languages (20):**  
ğŸ‡ºğŸ‡¸ ğŸ‡©ğŸ‡ª ğŸ‡«ğŸ‡· ğŸ‡ªğŸ‡¸ ğŸ‡µğŸ‡¹ ğŸ‡³ğŸ‡± ğŸ‡©ğŸ‡° ğŸ‡«ğŸ‡® ğŸ‡³ğŸ‡´ ğŸ‡µğŸ‡± ğŸ‡¨ğŸ‡¿ ğŸ‡¸ğŸ‡° ğŸ‡­ğŸ‡º ğŸ‡·ğŸ‡´ ğŸ‡·ğŸ‡º ğŸ‡¸ğŸ‡¦ ğŸ‡®ğŸ‡³ ğŸ‡¹ğŸ‡· ğŸ‡»ğŸ‡³ ğŸ‡¨ğŸ‡³ ğŸ‡®ğŸ‡©

*TTS button appears automatically for supported languages*

---

## ğŸ› ï¸ For Developers

### Local Development
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env  # Configure your servers
python run.py
```

### API Endpoints
```bash
POST /api/translate     # Main translation
POST /api/tts          # Text-to-speech  
POST /api/alternatives # Word alternatives
POST /api/history/save # Save translation
```

### Common Issues

**Can't connect to Ollama?**
- Check `OLLAMA_HOST` in your `.env` file
- Verify Ollama is running: `curl http://your-ollama:11434/api/tags`
- For Docker Desktop: use `host.docker.internal:11434`

**TTS not working?**  
- Verify `WYOMING_PIPER_HOST` is set correctly
- Check if your language is supported (see TTS section above)
- TTS button only appears for supported languages

**Model download slow?**
- Use `docker exec llot-ollama ollama pull gemma3:27b` to pre-download
- Consider using smaller models like `mistral:7b` for testing

---

## ğŸŒŸ Community

**Found LLOT useful?** 

â­ **Star this repo** to support development  
ğŸ› **Report issues** on [GitHub Issues](https://github.com/pawelwiejkut/llot/issues)  
ğŸ’¬ **Discuss on** [r/selfhosted](https://reddit.com/r/selfhosted)  
ğŸ”§ **Contribute** - PRs welcome!

---

## ğŸ“œ License

**MIT License** - Use commercially, modify freely, share with attribution.

---

<div align="center">

**ğŸ  Made for the self-hosted community**

[![GitHub stars](https://img.shields.io/github/stars/pawelwiejkut/llot?style=social)](https://github.com/pawelwiejkut/llot/stargazers)
[![Docker Pulls](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](https://github.com/pawelwiejkut/llot)

---

### ğŸ“Š Quick Stats
**40+ UI Languages** â€¢ **20+ TTS Languages** â€¢ **3 Deployment Options** â€¢ **100% Privacy**

*Join the hundreds of self-hosters using LLOT for private translation* 

</div>