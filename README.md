# ğŸŒ LLOT - Local LLM Ollama Translator

> **Privacy-first AI translation service powered by local LLM models**  
> âœ¨ No API keys â€¢ No cloud services â€¢ No data collection â€¢ 100% self-hosted âœ¨

[![Self-Hosted](https://img.shields.io/badge/Self--Hosted-100%25-green?style=for-the-badge&logo=docker)](https://github.com/pawelwiejkut/llot)
[![Languages](https://img.shields.io/badge/Languages-65%2B-blue?style=for-the-badge)](https://github.com/pawelwiejkut/llot)
[![Privacy](https://img.shields.io/badge/Privacy-First-red?style=for-the-badge&logo=shield)](https://github.com/pawelwiejkut/llot)
[![Modern UI](https://img.shields.io/badge/Modern-UI-purple?style=for-the-badge)](https://github.com/pawelwiejkut/llot)

---

## ğŸ“¸ Modern Interface

### ğŸ¨ Light Mode
![LLOT Main Interface](docs/images/main-interface.png)
*Clean, intuitive interface with real-time translation*

![LLOT Translation Result](docs/images/translation-result.png)
*Translation in action - powered by local AI models*

### ğŸŒ™ Dark Mode  
![LLOT Dark Mode](docs/images/dark-mode.png)
*Beautiful dark theme for comfortable nighttime use*

### ğŸ“± Mobile Responsive
![LLOT Mobile Interface](docs/images/mobile-interface.png)
*Perfect mobile experience - translate on any device*

---

## âœ¨ Why Choose LLOT?

| ğŸ”’ **Complete Privacy** | âš¡ **Lightning Performance** | ğŸ  **Homelab Perfect** |
|:---:|:---:|:---:|
| Your data never leaves your network | Instant translation with local AI | Docker deployment in under 5 minutes |
| No cloud APIs or tracking | Real-time as-you-type translation | Uses your existing Ollama server |
| Zero external dependencies | Smart language auto-detection | Lightweight Python Flask app |

| ğŸŒ **65+ Languages** | ğŸ”Š **Neural TTS** | ğŸ›ï¸ **Full Control** |
|:---:|:---:|:---:|
| Major world languages supported | High-quality speech synthesis | Choose your AI models |
| Auto language detection | 20+ TTS voices via Wyoming Piper | Configurable tone & style |
| Custom language filtering | Crystal-clear pronunciation | Your hardware, your rules |

---

## ğŸš€ Quick Start

### ğŸ¯ Option 1: Use Your Existing Ollama Server
```bash
git clone https://github.com/pawelwiejkut/llot.git
cd llot

# Configure your Ollama server
echo "OLLAMA_HOST=http://your-ollama-server:11434" > .env
echo "OL_MODEL=llama3.2:3b" >> .env  # or your preferred model

# Start LLOT
docker-compose up -d

# Access at http://localhost:8080
```

### ğŸ”§ Option 2: Complete Local Setup
```bash
git clone https://github.com/pawelwiejkut/llot.git
cd llot

# Includes Ollama + Wyoming Piper TTS
docker-compose -f docker-compose.full.yml up -d

# Access at http://localhost:8080
```

### âš™ï¸ Option 3: Native Installation
```bash
git clone https://github.com/pawelwiejkut/llot.git
cd llot

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
nano .env  # Edit your settings

# Run application
python run.py
```

---

## ğŸ›ï¸ Features

### ğŸŒ **Translation Engine**
- **Real-time translation** as you type
- **65+ languages** supported
- **Auto language detection** powered by `langdetect`
- **Multiple tones**: neutral, formal, informal, friendly, technical, poetic
- **Model switching** - use any Ollama-compatible LLM
- **Translation history** with quick recall
- **Alternative suggestions** for better translations
- **Smart refinement** with user constraints

### ğŸ¨ **Modern Interface**
- **Clean, responsive design** inspired by modern translation services
- **Dark/light theme** toggle
- **Mobile-first** responsive layout
- **Keyboard shortcuts** for power users
- **Real-time status** indicators
- **Copy to clipboard** with one click
- **Character counter** and smart layout

### ğŸ”Š **Text-to-Speech**
- **High-quality neural TTS** via Wyoming Piper
- **20+ language voices** with natural pronunciation
- **Source and target** text playback
- **Caching system** for improved performance

### ğŸ› ï¸ **Technical Excellence**
- **Modern Python** Flask application
- **Clean, refactored codebase** with proper error handling
- **Comprehensive test suite** with automated UI testing
- **Docker deployment** with multiple configurations
- **Environment-based configuration**
- **Health monitoring** and status checks
- **Detailed logging** for troubleshooting

---

## ğŸ”§ Configuration

### Environment Variables

Create `.env` file in project root:

```bash
# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OL_MODEL=llama3.2:3b

# Application Settings
APP_HOST=0.0.0.0
APP_PORT=8080
FLASK_DEBUG=0

# TTS Configuration (optional)
WYOMING_PIPER_HOST=localhost
WYOMING_PIPER_PORT=10200

# Language Filtering (optional)
TRANSLATION_LANGUAGES=en,de,fr,es,it,pt,pl,ru,zh,ja,ko,ar,hi

# Debug Settings
DEBUG_LOGGING=false
```

### Supported Models

LLOT works with any Ollama-compatible model. Recommended models:

| Model | Size | Speed | Quality | Best For |
|-------|------|--------|---------|----------|
| `llama3.2:3b` | 2GB | âš¡âš¡âš¡ | â­â­â­ | Fast translation |
| `llama3.1:8b` | 4.7GB | âš¡âš¡ | â­â­â­â­ | Balanced performance |
| `gemma2:9b` | 5.4GB | âš¡âš¡ | â­â­â­â­ | High quality |
| `qwen2.5:14b` | 8.2GB | âš¡ | â­â­â­â­â­ | Professional use |

---

## ğŸ³ Docker Deployment

### Standard Setup (Use Existing Ollama)
```yaml
version: '3.8'
services:
  llot:
    build: .
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_HOST=http://your-ollama-server:11434
      - OL_MODEL=llama3.2:3b
    volumes:
      - ./logs:/app/logs
```

### Full Setup (Includes Ollama + TTS)
```bash
# Launches everything you need
docker-compose -f docker-compose.full.yml up -d
```

---

## ğŸŒ Supported Languages

**65+ languages supported** with smart auto-detection:

### Major Languages
ğŸ‡ºğŸ‡¸ English â€¢ ğŸ‡¨ğŸ‡³ ä¸­æ–‡ (Chinese) â€¢ ğŸ‡®ğŸ‡³ à¤¹à¤¿à¤¨à¥à¤¦à¥€ (Hindi) â€¢ ğŸ‡ªğŸ‡¸ EspaÃ±ol â€¢ ğŸ‡«ğŸ‡· FranÃ§ais â€¢ ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Arabic)  
ğŸ‡®ğŸ‡³ à¦¬à¦¾à¦‚à¦²à¦¾ (Bengali) â€¢ ğŸ‡µğŸ‡¹ PortuguÃªs â€¢ ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹ â€¢ ğŸ‡µğŸ‡° Ø§Ø±Ø¯Ùˆ (Urdu) â€¢ ğŸ‡®ğŸ‡© Bahasa Indonesia  
ğŸ‡©ğŸ‡ª Deutsch â€¢ ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª â€¢ ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e â€¢ ğŸ‡°ğŸ‡· í•œêµ­ì–´ â€¢ ğŸ‡»ğŸ‡³ Tiáº¿ng Viá»‡t â€¢ ğŸ‡®ğŸ‡³ à®¤à®®à®¿à®´à¯ (Tamil) â€¢ ğŸ‡¹ğŸ‡­ à¹„à¸—à¸¢

### European Languages  
ğŸ‡µğŸ‡± Polski â€¢ ğŸ‡®ğŸ‡¹ Italiano â€¢ ğŸ‡³ğŸ‡± Nederlands â€¢ ğŸ‡¸ğŸ‡ª Svenska â€¢ ğŸ‡©ğŸ‡° Dansk â€¢ ğŸ‡³ğŸ‡´ Norsk â€¢ ğŸ‡«ğŸ‡® Suomi  
ğŸ‡¨ğŸ‡¿ ÄŒeÅ¡tina â€¢ ğŸ‡¸ğŸ‡° SlovenÄina â€¢ ğŸ‡­ğŸ‡º Magyar â€¢ ğŸ‡·ğŸ‡´ RomÃ¢nÄƒ â€¢ ğŸ‡§ğŸ‡¬ Ğ‘ÑŠĞ»Ğ³Ğ°Ñ€ÑĞºĞ¸ â€¢ ğŸ‡­ğŸ‡· Hrvatski  
ğŸ‡¸ğŸ‡® SlovenÅ¡Äina â€¢ ğŸ‡±ğŸ‡» LatvieÅ¡u â€¢ ğŸ‡±ğŸ‡¹ LietuviÅ³ â€¢ ğŸ‡ªğŸ‡ª Eesti â€¢ ğŸ‡¬ğŸ‡· Î•Î»Î»Î·Î½Î¹ÎºÎ¬ â€¢ ğŸ‡²ğŸ‡¹ Malti â€¢ ğŸ‡®ğŸ‡ª Gaeilge

**Language filtering available** - configure only the languages you need.

---

## ğŸ”Š Text-to-Speech Support

### Supported TTS Languages
- **English** (US) - Multiple voices
- **German** (DE) - Professional quality  
- **French** (FR) - Natural pronunciation
- **Spanish** (ES) - Clear articulation
- **Portuguese** (BR) - Brazilian accent
- **Polish** (PL) - Native speaker quality
- **And 15+ more languages**

### TTS Setup
```bash
# Install Wyoming Piper (if not using Docker)
pip install wyoming-piper

# Start TTS service
wyoming-piper --voice pl_PL-darkman-medium --port 10200

# Configure LLOT
echo "WYOMING_PIPER_HOST=localhost" >> .env
echo "WYOMING_PIPER_PORT=10200" >> .env
```

---

## ğŸ§ª Testing & Quality

### Comprehensive Test Suite
```bash
# Unit tests
python -m pytest tests/ -v

# Comprehensive UI tests
python tests/comprehensive_app_tests.py

# Generate test reports
python tests/comprehensive_app_tests_extended.py
```

### Test Coverage
- âœ… **API Endpoints** - All translation, history, TTS endpoints
- âœ… **UI Functionality** - Language selection, dark mode, mobile responsive
- âœ… **Error Handling** - Empty inputs, server errors, timeouts
- âœ… **Performance** - Translation speed, page load times
- âœ… **Accessibility** - Keyboard navigation, screen readers

---

## âš¡ Performance

### Benchmarks
- **Page Load**: ~50ms
- **Translation Speed**: 2-15s (model dependent)
- **Memory Usage**: ~200MB (excluding models)
- **TTS Generation**: ~1-3s per sentence

### Optimization Tips
1. **Use faster models** like `llama3.2:3b` for speed
2. **Enable TTS caching** (enabled by default)
3. **Configure language filtering** to reduce options
4. **Use SSD storage** for model loading
5. **Increase RAM** for larger models

---

## ğŸ”§ Development

### Local Development
```bash
# Clone and setup
git clone https://github.com/pawelwiejkut/llot.git
cd llot

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or: venv\Scripts\activate  # Windows

# Install dependencies
pip install -r requirements.txt

# Setup environment
cp .env.example .env

# Run in development mode
export FLASK_DEBUG=1
python run.py
```

### Code Structure
```
llot/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py           # Flask app factory
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ routes/               # API and web routes
â”‚   â”‚   â”œâ”€â”€ main.py          # Main web routes
â”‚   â”‚   â”œâ”€â”€ api.py           # Translation API
â”‚   â”‚   â””â”€â”€ favicon.py       # Static asset routes
â”‚   â”œâ”€â”€ services/            # Business logic
â”‚   â”‚   â”œâ”€â”€ translator.py    # Translation service
â”‚   â”‚   â”œâ”€â”€ ollama_client.py # Ollama API client
â”‚   â”‚   â””â”€â”€ language_detector.py # Language detection
â”‚   â”œâ”€â”€ models/              # Data models
â”‚   â”‚   â”œâ”€â”€ history.py       # Translation history
â”‚   â”‚   â””â”€â”€ language.py      # Language definitions
â”‚   â”œâ”€â”€ static/              # Frontend assets
â”‚   â”‚   â”œâ”€â”€ css/style-modern.css # Modern UI styles
â”‚   â”‚   â””â”€â”€ js/app-modern.js  # Modern UI JavaScript
â”‚   â””â”€â”€ templates/           # Jinja2 templates
â”‚       â”œâ”€â”€ index-modern.html # Modern UI template
â”‚       â””â”€â”€ backup/          # Classic UI backup
â”œâ”€â”€ tests/                   # Test suites
â”œâ”€â”€ docs/                    # Documentation
â””â”€â”€ docker-compose.yml      # Docker configuration
```

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### ğŸ› Bug Reports
- Use the issue template
- Include screenshots if UI-related
- Provide environment details
- Add reproduction steps

### âœ¨ Feature Requests  
- Check existing issues first
- Explain the use case
- Consider implementation complexity
- Provide mockups if UI-related

### ğŸ”§ Code Contributions
1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Make changes with tests
4. Run test suite: `python -m pytest`
5. Submit pull request

### ğŸŒ Translations
Help translate LLOT interface:
1. Copy `app/translations/messages.pot`
2. Create new language folder
3. Translate strings using poedit or manually
4. Submit as pull request

---

## ğŸ“š API Documentation

### Translation Endpoint
```bash
POST /api/translate
Content-Type: application/json

{
  "source_text": "Hello world",
  "source_lang": "en",    # or "auto"
  "target_lang": "pl", 
  "tone": "neutral"       # optional
}

# Response
{
  "translated_text": "Witaj Å›wiecie",
  "source_lang": "en",
  "target_lang": "pl"
}
```

### Text-to-Speech Endpoint
```bash
POST /api/tts
Content-Type: application/json

{
  "text": "Witaj Å›wiecie",
  "language": "pl"
}

# Response: audio/wav binary data
```

### Health Check
```bash
GET /api/health

# Response
{
  "ollama": {"status": "ok", "models": [...]},
  "tts": {"status": "ok"},
  "overall": "ok"
}
```

---

## ğŸ› Troubleshooting

### Common Issues

**Translation not working?**
- âœ… Check Ollama server is running: `curl http://localhost:11434/api/tags`
- âœ… Verify model is available: `ollama list`
- âœ… Check LLOT logs: `docker-compose logs llot`

**TTS not working?**
- âœ… Verify Wyoming Piper is running: `curl http://localhost:10200`
- âœ… Check TTS configuration in `.env`
- âœ… Test direct API: `curl -X POST http://localhost:8080/api/tts -d '{"text":"test","language":"en"}'`

**UI issues?**
- âœ… Clear browser cache and refresh
- âœ… Check browser console for JavaScript errors
- âœ… Verify all static assets are loading

**Performance issues?**
- âœ… Use smaller, faster models (e.g., `llama3.2:3b`)
- âœ… Increase system RAM
- âœ… Check available disk space
- âœ… Monitor system resources

### Debug Mode
```bash
# Enable detailed logging
echo "DEBUG_LOGGING=true" >> .env
echo "FLASK_DEBUG=1" >> .env

# Restart application
docker-compose restart
```

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## â­ Support the Project

If LLOT helps you achieve translation privacy and independence:

- â­ **Star this repository** 
- ğŸ› **Report issues** to help improve quality
- ğŸ”§ **Contribute code** or documentation
- ğŸŒ **Share with the self-hosting community**

---

## ğŸ™ Acknowledgments

- **[Ollama](https://ollama.com)** - For making local LLM deployment simple
- **[Wyoming Piper](https://github.com/rhasspy/wyoming-piper)** - For excellent local TTS
- **[Flask](https://flask.palletsprojects.com)** - For the robust web framework
- **[langdetect](https://github.com/Mimino666/langdetect)** - For language detection
- **Self-hosting community** - For inspiring privacy-first solutions

---

<div align="center">

**ğŸ  Made for Self-Hosters, by Self-Hosters**

**ğŸ”’ Your Data â€¢ ğŸ  Your Network â€¢ âš¡ Your Speed**

[ğŸš€ Get Started](#-quick-start) â€¢ [ğŸ“– Documentation](#-api-documentation) â€¢ [ğŸ› Issues](https://github.com/pawelwiejkut/llot/issues) â€¢ [ğŸ’¬ Discussions](https://github.com/pawelwiejkut/llot/discussions)

</div>